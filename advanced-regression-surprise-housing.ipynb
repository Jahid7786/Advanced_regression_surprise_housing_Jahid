{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "<h1> ADVANCED REGRESSION ASSIGNMENT</h1>\n",
    "\n",
    "<h2>Submitted by: Jahid Khan </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color= coral> Housing Price Prediction Assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=purple>Problem Statement - Part I</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Part-I\n",
    "\n",
    "- A US-based housing company named Surprise Housing has decided to enter the Australian market. The company uses data analytics to purchase houses at a price below their actual values and flip them on at a higher price. For the same purpose, the company has collected a data set from the sale of houses in Australia. The data is provided in the CSV file below.\n",
    "\n",
    " \n",
    "\n",
    "- The company is looking at prospective properties to buy to enter the market. You are required to build a regression model using regularisation in order to predict the actual value of the prospective properties and decide whether to invest in them or not.\n",
    "\n",
    " \n",
    "\n",
    "- The company wants to know the following things about the prospective properties:\n",
    "\n",
    "   - `Which variables are significant in predicting the price of a house`, and\n",
    "\n",
    "   - `How well those variables describe the price of a house`.\n",
    "\n",
    " \n",
    "\n",
    "- Also, determine the `optimal value of lambda for ridge and lasso regression`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Goal \n",
    "\n",
    " \n",
    "\n",
    "You are required to model the price of houses with the available independent variables. This model will then be used by the management to understand how exactly the prices vary with the variables. They can accordingly manipulate the strategy of the firm and concentrate on areas that will yield high returns. Further, the model will be a good way for management to understand the pricing dynamics of a new market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=purple>Problem Statement - Part II</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Part-II\n",
    "\n",
    "- The following questions are the second part of the graded assignment. \n",
    "\n",
    "- Please limit your answers to **less than 500 words per question**.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the optimal value of alpha for ridge and lasso regression? What will be the changes in the model if you choose double the value of alpha for both ridge and lasso? What will be the most important predictor variables after the change is implemented?\n",
    "\n",
    " \n",
    "\n",
    "### Question 2\n",
    "\n",
    "You have determined the optimal value of lambda for ridge and lasso regression during the assignment. Now, which one will you choose to apply and why?\n",
    "\n",
    " \n",
    "\n",
    "### Question 3\n",
    "\n",
    "After building the model, you realised that the five most important predictor variables in the lasso model are not available in the incoming data. You will now have to create another model excluding the five most important predictor variables. Which are the five most important predictor variables now?\n",
    "\n",
    " \n",
    "\n",
    "### Question 4\n",
    "\n",
    "How can you make sure that a model is robust and generalisable? What are the implications of the same for the accuracy of the model and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _______________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🌊 Flow of this notebook\n",
    "\n",
    "### 1) Read and Understand the data\n",
    "\n",
    "### 2) Data Exploration\n",
    "\n",
    "- Univariate Analysis\n",
    "- Bivariate Analysis\n",
    "\n",
    "### 3) Feature Engineering\n",
    "\n",
    "### 4) Data Preprocessing\n",
    "\n",
    "- Missing Value Treatment\n",
    "- Dummy Variable Creation\n",
    "- Outlier Treatment\n",
    "\n",
    "### 5) Model Building, Tuning & Evaluation\n",
    "\n",
    "- Split the Data into Dependent and Independent variables\n",
    "- Train - Test Split\n",
    "- Scaling numerical columns\n",
    "\n",
    "\n",
    "\n",
    "- Model 1: Ridge Regression\n",
    "\n",
    "- Model 2: Lasso\n",
    "\n",
    "\n",
    "### 6) Comparing the two models\n",
    "\n",
    "### 7) Inferences for 'Surprise Housing' \n",
    "\n",
    "### 8) Coding for answering the subjective questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📚 Load Libraries 📚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T14:47:09.474745Z",
     "iopub.status.busy": "2023-12-13T14:47:09.474261Z",
     "iopub.status.idle": "2023-12-13T14:47:10.742763Z",
     "shell.execute_reply": "2023-12-13T14:47:10.741593Z",
     "shell.execute_reply.started": "2023-12-13T14:47:09.474646Z"
    }
   },
   "outputs": [],
   "source": [
    "## Import requisite libraries\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T14:47:10.744811Z",
     "iopub.status.busy": "2023-12-13T14:47:10.744462Z",
     "iopub.status.idle": "2023-12-13T14:47:10.749135Z",
     "shell.execute_reply": "2023-12-13T14:47:10.748310Z",
     "shell.execute_reply.started": "2023-12-13T14:47:10.744776Z"
    }
   },
   "outputs": [],
   "source": [
    "## Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T14:47:10.751157Z",
     "iopub.status.busy": "2023-12-13T14:47:10.750819Z",
     "iopub.status.idle": "2023-12-13T14:47:10.761317Z",
     "shell.execute_reply": "2023-12-13T14:47:10.760131Z",
     "shell.execute_reply.started": "2023-12-13T14:47:10.751126Z"
    }
   },
   "outputs": [],
   "source": [
    "## Set display limits\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=cornflowerblue>Step 1:   🤔 Read and Understand the Data   🤔</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T14:47:10.765746Z",
     "iopub.status.busy": "2023-12-13T14:47:10.765405Z",
     "iopub.status.idle": "2023-12-13T14:47:10.940633Z",
     "shell.execute_reply": "2023-12-13T14:47:10.935336Z",
     "shell.execute_reply.started": "2023-12-13T14:47:10.765714Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/surprise-housing-data/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7d4660459098>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Load the csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/surprise-housing-data/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## View the first five rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         )\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m             )\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/surprise-housing-data/train.csv'"
     ]
    }
   ],
   "source": [
    "## Load the csv file\n",
    "df = pd.read_csv('../input/surprise-housing-data/train.csv')\n",
    "\n",
    "## View the first five rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.941643Z",
     "iopub.status.idle": "2023-12-13T14:47:10.942145Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check the dimensions\n",
    "print(\"Number of Rows = \", df.shape[0])\n",
    "print(\"Number of Columns = \", df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "Following is the explanation of all the variables/features:-\n",
    "\n",
    "\n",
    "\n",
    "**MSSubClass**: Identifies the type of dwelling involved in the sale.\t\n",
    "\n",
    "        20\t1-STORY 1946 & NEWER ALL STYLES\n",
    "        30\t1-STORY 1945 & OLDER\n",
    "        40\t1-STORY W/FINISHED ATTIC ALL AGES\n",
    "        45\t1-1/2 STORY - UNFINISHED ALL AGES\n",
    "        50\t1-1/2 STORY FINISHED ALL AGES\n",
    "        60\t2-STORY 1946 & NEWER\n",
    "        70\t2-STORY 1945 & OLDER\n",
    "        75\t2-1/2 STORY ALL AGES\n",
    "        80\tSPLIT OR MULTI-LEVEL\n",
    "        85\tSPLIT FOYER\n",
    "        90\tDUPLEX - ALL STYLES AND AGES\n",
    "       120\t1-STORY PUD (Planned Unit Development) - 1946 & NEWER\n",
    "       150\t1-1/2 STORY PUD - ALL AGES\n",
    "       160\t2-STORY PUD - 1946 & NEWER\n",
    "       180\tPUD - MULTILEVEL - INCL SPLIT LEV/FOYER\n",
    "       190\t2 FAMILY CONVERSION - ALL STYLES AND AGES\n",
    "\n",
    "**MSZoning**: Identifies the general zoning classification of the sale.\n",
    "\t\t\n",
    "       A\tAgriculture\n",
    "       C\tCommercial\n",
    "       FV\tFloating Village Residential\n",
    "       I\tIndustrial\n",
    "       RH\tResidential High Density\n",
    "       RL\tResidential Low Density\n",
    "       RP\tResidential Low Density Park \n",
    "       RM\tResidential Medium Density\n",
    "\t\n",
    "**LotFrontage**: Linear feet of street connected to property\n",
    "\n",
    "**LotArea**: Lot size in square feet\n",
    "\n",
    "**Street**: Type of road access to property\n",
    "\n",
    "       Grvl\tGravel\t\n",
    "       Pave\tPaved\n",
    "       \t\n",
    "**Alley**: Type of alley access to property\n",
    "\n",
    "       Grvl\tGravel\n",
    "       Pave\tPaved\n",
    "       NA \tNo alley access\n",
    "\t\t\n",
    "**LotShape**: General shape of property\n",
    "\n",
    "       Reg\tRegular\t\n",
    "       IR1\tSlightly irregular\n",
    "       IR2\tModerately Irregular\n",
    "       IR3\tIrregular\n",
    "       \n",
    "**LandContour**: Flatness of the property\n",
    "\n",
    "       Lvl\tNear Flat/Level\t\n",
    "       Bnk\tBanked - Quick and significant rise from street grade to building\n",
    "       HLS\tHillside - Significant slope from side to side\n",
    "       Low\tDepression\n",
    "\t\t\n",
    "**Utilities**: Type of utilities available\n",
    "\t\t\n",
    "       AllPub\tAll public Utilities (E,G,W,& S)\t\n",
    "       NoSewr\tElectricity, Gas, and Water (Septic Tank)\n",
    "       NoSeWa\tElectricity and Gas Only\n",
    "       ELO\tElectricity only\t\n",
    "\t\n",
    "**LotConfig**: Lot configuration\n",
    "\n",
    "       Inside\tInside lot\n",
    "       Corner\tCorner lot\n",
    "       CulDSac\tCul-de-sac\n",
    "       FR2\tFrontage on 2 sides of property\n",
    "       FR3\tFrontage on 3 sides of property\n",
    "\t\n",
    "**LandSlope**: Slope of property\n",
    "\t\t\n",
    "       Gtl\tGentle slope\n",
    "       Mod\tModerate Slope\t\n",
    "       Sev\tSevere Slope\n",
    "\t\n",
    "**Neighborhood**: Physical locations within Ames city limits\n",
    "\n",
    "       Blmngtn\tBloomington Heights\n",
    "       Blueste\tBluestem\n",
    "       BrDale\tBriardale\n",
    "       BrkSide\tBrookside\n",
    "       ClearCr\tClear Creek\n",
    "       CollgCr\tCollege Creek\n",
    "       Crawfor\tCrawford\n",
    "       Edwards\tEdwards\n",
    "       Gilbert\tGilbert\n",
    "       IDOTRR\tIowa DOT and Rail Road\n",
    "       MeadowV\tMeadow Village\n",
    "       Mitchel\tMitchell\n",
    "       Names\tNorth Ames\n",
    "       NoRidge\tNorthridge\n",
    "       NPkVill\tNorthpark Villa\n",
    "       NridgHt\tNorthridge Heights\n",
    "       NWAmes\tNorthwest Ames\n",
    "       OldTown\tOld Town\n",
    "       SWISU\tSouth & West of Iowa State University\n",
    "       Sawyer\tSawyer\n",
    "       SawyerW\tSawyer West\n",
    "       Somerst\tSomerset\n",
    "       StoneBr\tStone Brook\n",
    "       Timber\tTimberland\n",
    "       Veenker\tVeenker\n",
    "\t\t\t\n",
    "**Condition1**: Proximity to various conditions\n",
    "\t\n",
    "       Artery\tAdjacent to arterial street\n",
    "       Feedr\tAdjacent to feeder street\t\n",
    "       Norm\tNormal\t\n",
    "       RRNn\tWithin 200' of North-South Railroad\n",
    "       RRAn\tAdjacent to North-South Railroad\n",
    "       PosN\tNear positive off-site feature--park, greenbelt, etc.\n",
    "       PosA\tAdjacent to postive off-site feature\n",
    "       RRNe\tWithin 200' of East-West Railroad\n",
    "       RRAe\tAdjacent to East-West Railroad\n",
    "\t\n",
    "**Condition2**: Proximity to various conditions (if more than one is present)\n",
    "\t\t\n",
    "       Artery\tAdjacent to arterial street\n",
    "       Feedr\tAdjacent to feeder street\t\n",
    "       Norm\tNormal\t\n",
    "       RRNn\tWithin 200' of North-South Railroad\n",
    "       RRAn\tAdjacent to North-South Railroad\n",
    "       PosN\tNear positive off-site feature--park, greenbelt, etc.\n",
    "       PosA\tAdjacent to postive off-site feature\n",
    "       RRNe\tWithin 200' of East-West Railroad\n",
    "       RRAe\tAdjacent to East-West Railroad\n",
    "\t\n",
    "**BldgType**: Type of dwelling\n",
    "\t\t\n",
    "       1Fam\tSingle-family Detached\t\n",
    "       2FmCon\tTwo-family Conversion; originally built as one-family dwelling\n",
    "       Duplx\tDuplex\n",
    "       TwnhsE\tTownhouse End Unit\n",
    "       TwnhsI\tTownhouse Inside Unit\n",
    "\t\n",
    "**HouseStyle**: Style of dwelling\n",
    "\t\n",
    "       1Story\tOne story\n",
    "       1.5Fin\tOne and one-half story: 2nd level finished\n",
    "       1.5Unf\tOne and one-half story: 2nd level unfinished\n",
    "       2Story\tTwo story\n",
    "       2.5Fin\tTwo and one-half story: 2nd level finished\n",
    "       2.5Unf\tTwo and one-half story: 2nd level unfinished\n",
    "       SFoyer\tSplit Foyer\n",
    "       SLvl\tSplit Level\n",
    "\t\n",
    "**OverallQual**: Rates the overall material and finish of the house\n",
    "\n",
    "       10\tVery Excellent\n",
    "       9\tExcellent\n",
    "       8\tVery Good\n",
    "       7\tGood\n",
    "       6\tAbove Average\n",
    "       5\tAverage\n",
    "       4\tBelow Average\n",
    "       3\tFair\n",
    "       2\tPoor\n",
    "       1\tVery Poor\n",
    "\t\n",
    "**OverallCond**: Rates the overall condition of the house\n",
    "\n",
    "       10\tVery Excellent\n",
    "       9\tExcellent\n",
    "       8\tVery Good\n",
    "       7\tGood\n",
    "       6\tAbove Average\t\n",
    "       5\tAverage\n",
    "       4\tBelow Average\t\n",
    "       3\tFair\n",
    "       2\tPoor\n",
    "       1\tVery Poor\n",
    "\t\t\n",
    "**YearBuilt**: Original construction date\n",
    "\n",
    "**YearRemodAdd**: Remodel date (same as construction date if no remodeling or additions)\n",
    "\n",
    "**RoofStyle**: Type of roof\n",
    "\n",
    "       Flat\tFlat\n",
    "       Gable\tGable\n",
    "       Gambrel\tGabrel (Barn)\n",
    "       Hip\tHip\n",
    "       Mansard\tMansard\n",
    "       Shed\tShed\n",
    "\t\t\n",
    "**RoofMatl**: Roof material\n",
    "\n",
    "       ClyTile\tClay or Tile\n",
    "       CompShg\tStandard (Composite) Shingle\n",
    "       Membran\tMembrane\n",
    "       Metal\tMetal\n",
    "       Roll\tRoll\n",
    "       Tar&Grv\tGravel & Tar\n",
    "       WdShake\tWood Shakes\n",
    "       WdShngl\tWood Shingles\n",
    "\t\t\n",
    "**Exterior1st**: Exterior covering on house\n",
    "\n",
    "       AsbShng\tAsbestos Shingles\n",
    "       AsphShn\tAsphalt Shingles\n",
    "       BrkComm\tBrick Common\n",
    "       BrkFace\tBrick Face\n",
    "       CBlock\tCinder Block\n",
    "       CemntBd\tCement Board\n",
    "       HdBoard\tHard Board\n",
    "       ImStucc\tImitation Stucco\n",
    "       MetalSd\tMetal Siding\n",
    "       Other\tOther\n",
    "       Plywood\tPlywood\n",
    "       PreCast\tPreCast\t\n",
    "       Stone\tStone\n",
    "       Stucco\tStucco\n",
    "       VinylSd\tVinyl Siding\n",
    "       Wd Sdng\tWood Siding\n",
    "       WdShing\tWood Shingles\n",
    "\t\n",
    "**Exterior2nd**: Exterior covering on house (if more than one material)\n",
    "\n",
    "       AsbShng\tAsbestos Shingles\n",
    "       AsphShn\tAsphalt Shingles\n",
    "       BrkComm\tBrick Common\n",
    "       BrkFace\tBrick Face\n",
    "       CBlock\tCinder Block\n",
    "       CemntBd\tCement Board\n",
    "       HdBoard\tHard Board\n",
    "       ImStucc\tImitation Stucco\n",
    "       MetalSd\tMetal Siding\n",
    "       Other\tOther\n",
    "       Plywood\tPlywood\n",
    "       PreCast\tPreCast\n",
    "       Stone\tStone\n",
    "       Stucco\tStucco\n",
    "       VinylSd\tVinyl Siding\n",
    "       Wd Sdng\tWood Siding\n",
    "       WdShing\tWood Shingles\n",
    "\t\n",
    "**MasVnrType**: Masonry veneer type\n",
    "\n",
    "       BrkCmn\tBrick Common\n",
    "       BrkFace\tBrick Face\n",
    "       CBlock\tCinder Block\n",
    "       None\tNone\n",
    "       Stone\tStone\n",
    "\t\n",
    "**MasVnrArea**: Masonry veneer area in square feet\n",
    "\n",
    "**ExterQual**: Evaluates the quality of the material on the exterior \n",
    "\t\t\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tAverage/Typical\n",
    "       Fa\tFair\n",
    "       Po\tPoor\n",
    "\t\t\n",
    "**ExterCond**: Evaluates the present condition of the material on the exterior\n",
    "\t\t\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tAverage/Typical\n",
    "       Fa\tFair\n",
    "       Po\tPoor\n",
    "\t\t\n",
    "**Foundation**: Type of foundation\n",
    "\t\t\n",
    "       BrkTil\tBrick & Tile\n",
    "       CBlock\tCinder Block\n",
    "       PConc\tPoured Contrete\t\n",
    "       Slab\tSlab\n",
    "       Stone\tStone\n",
    "       Wood\tWood\n",
    "\t\t\n",
    "**BsmtQual**: Evaluates the height of the basement\n",
    "\n",
    "       Ex\tExcellent (100+ inches)\t\n",
    "       Gd\tGood (90-99 inches)\n",
    "       TA\tTypical (80-89 inches)\n",
    "       Fa\tFair (70-79 inches)\n",
    "       Po\tPoor (<70 inches\n",
    "       NA\tNo Basement\n",
    "\t\t\n",
    "**BsmtCond**: Evaluates the general condition of the basement\n",
    "\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tTypical - slight dampness allowed\n",
    "       Fa\tFair - dampness or some cracking or settling\n",
    "       Po\tPoor - Severe cracking, settling, or wetness\n",
    "       NA\tNo Basement\n",
    "\t\n",
    "**BsmtExposure**: Refers to walkout or garden level walls\n",
    "\n",
    "       Gd\tGood Exposure\n",
    "       Av\tAverage Exposure (split levels or foyers typically score average or above)\t\n",
    "       Mn\tMimimum Exposure\n",
    "       No\tNo Exposure\n",
    "       NA\tNo Basement\n",
    "\t\n",
    "**BsmtFinType1**: Rating of basement finished area\n",
    "\n",
    "       GLQ\tGood Living Quarters\n",
    "       ALQ\tAverage Living Quarters\n",
    "       BLQ\tBelow Average Living Quarters\t\n",
    "       Rec\tAverage Rec Room\n",
    "       LwQ\tLow Quality\n",
    "       Unf\tUnfinshed\n",
    "       NA\tNo Basement\n",
    "\t\t\n",
    "**BsmtFinSF1**: Type 1 finished square feet\n",
    "\n",
    "**BsmtFinType2**: Rating of basement finished area (if multiple types)\n",
    "\n",
    "       GLQ\tGood Living Quarters\n",
    "       ALQ\tAverage Living Quarters\n",
    "       BLQ\tBelow Average Living Quarters\t\n",
    "       Rec\tAverage Rec Room\n",
    "       LwQ\tLow Quality\n",
    "       Unf\tUnfinshed\n",
    "       NA\tNo Basement\n",
    "\n",
    "**BsmtFinSF2**: Type 2 finished square feet\n",
    "\n",
    "**BsmtUnfSF**: Unfinished square feet of basement area\n",
    "\n",
    "**TotalBsmtSF**: Total square feet of basement area\n",
    "\n",
    "**Heating**: Type of heating\n",
    "\t\t\n",
    "       Floor\tFloor Furnace\n",
    "       GasA\tGas forced warm air furnace\n",
    "       GasW\tGas hot water or steam heat\n",
    "       Grav\tGravity furnace\t\n",
    "       OthW\tHot water or steam heat other than gas\n",
    "       Wall\tWall furnace\n",
    "\t\t\n",
    "**HeatingQC**: Heating quality and condition\n",
    "\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tAverage/Typical\n",
    "       Fa\tFair\n",
    "       Po\tPoor\n",
    "\t\t\n",
    "**CentralAir**: Central air conditioning\n",
    "\n",
    "       N\tNo\n",
    "       Y\tYes\n",
    "\t\t\n",
    "**Electrical**: Electrical system\n",
    "\n",
    "       SBrkr\tStandard Circuit Breakers & Romex\n",
    "       FuseA\tFuse Box over 60 AMP and all Romex wiring (Average)\t\n",
    "       FuseF\t60 AMP Fuse Box and mostly Romex wiring (Fair)\n",
    "       FuseP\t60 AMP Fuse Box and mostly knob & tube wiring (poor)\n",
    "       Mix\tMixed\n",
    "\t\t\n",
    "**1stFlrSF**: First Floor square feet\n",
    " \n",
    "**2ndFlrSF**: Second floor square feet\n",
    "\n",
    "**LowQualFinSF**: Low quality finished square feet (all floors)\n",
    "\n",
    "**GrLivArea**: Above grade (ground) living area square feet\n",
    "\n",
    "**BsmtFullBath**: Basement full bathrooms\n",
    "\n",
    "**BsmtHalfBath**: Basement half bathrooms\n",
    "\n",
    "**FullBath**: Full bathrooms above grade\n",
    "\n",
    "**HalfBath**: Half baths above grade\n",
    "\n",
    "**Bedroom**: Bedrooms above grade (does NOT include basement bedrooms)\n",
    "\n",
    "**Kitchen**: Kitchens above grade\n",
    "\n",
    "**KitchenQual**: Kitchen quality\n",
    "\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tTypical/Average\n",
    "       Fa\tFair\n",
    "       Po\tPoor\n",
    "       \t\n",
    "**TotRmsAbvGrd**: Total rooms above grade (does not include bathrooms)\n",
    "\n",
    "**Functional**: Home functionality (Assume typical unless deductions are warranted)\n",
    "\n",
    "       Typ\tTypical Functionality\n",
    "       Min1\tMinor Deductions 1\n",
    "       Min2\tMinor Deductions 2\n",
    "       Mod\tModerate Deductions\n",
    "       Maj1\tMajor Deductions 1\n",
    "       Maj2\tMajor Deductions 2\n",
    "       Sev\tSeverely Damaged\n",
    "       Sal\tSalvage only\n",
    "\t\t\n",
    "**Fireplaces**: Number of fireplaces\n",
    "\n",
    "**FireplaceQu**: Fireplace quality\n",
    "\n",
    "       Ex\tExcellent - Exceptional Masonry Fireplace\n",
    "       Gd\tGood - Masonry Fireplace in main level\n",
    "       TA\tAverage - Prefabricated Fireplace in main living area or Masonry Fireplace in basement\n",
    "       Fa\tFair - Prefabricated Fireplace in basement\n",
    "       Po\tPoor - Ben Franklin Stove\n",
    "       NA\tNo Fireplace\n",
    "\t\t\n",
    "**GarageType**: Garage location\n",
    "\t\t\n",
    "       2Types\tMore than one type of garage\n",
    "       Attchd\tAttached to home\n",
    "       Basment\tBasement Garage\n",
    "       BuiltIn\tBuilt-In (Garage part of house - typically has room above garage)\n",
    "       CarPort\tCar Port\n",
    "       Detchd\tDetached from home\n",
    "       NA\tNo Garage\n",
    "\t\t\n",
    "**GarageYrBlt**: Year garage was built\n",
    "\t\t\n",
    "**GarageFinish**: Interior finish of the garage\n",
    "\n",
    "       Fin\tFinished\n",
    "       RFn\tRough Finished\t\n",
    "       Unf\tUnfinished\n",
    "       NA\tNo Garage\n",
    "\t\t\n",
    "**GarageCars**: Size of garage in car capacity\n",
    "\n",
    "**GarageArea**: Size of garage in square feet\n",
    "\n",
    "**GarageQual**: Garage quality\n",
    "\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tTypical/Average\n",
    "       Fa\tFair\n",
    "       Po\tPoor\n",
    "       NA\tNo Garage\n",
    "\t\t\n",
    "**GarageCond**: Garage condition\n",
    "\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tTypical/Average\n",
    "       Fa\tFair\n",
    "       Po\tPoor\n",
    "       NA\tNo Garage\n",
    "\t\t\n",
    "**PavedDrive**: Paved driveway\n",
    "\n",
    "       Y\tPaved \n",
    "       P\tPartial Pavement\n",
    "       N\tDirt/Gravel\n",
    "\t\t\n",
    "**WoodDeckSF**: Wood deck area in square feet\n",
    "\n",
    "**OpenPorchSF**: Open porch area in square feet\n",
    "\n",
    "**EnclosedPorch**: Enclosed porch area in square feet\n",
    "\n",
    "**3SsnPorch**: Three season porch area in square feet\n",
    "\n",
    "**ScreenPorch**: Screen porch area in square feet\n",
    "\n",
    "**PoolArea**: Pool area in square feet\n",
    "\n",
    "**PoolQC**: Pool quality\n",
    "\t\t\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tAverage/Typical\n",
    "       Fa\tFair\n",
    "       NA\tNo Pool\n",
    "\t\t\n",
    "**Fence**: Fence quality\n",
    "\t\t\n",
    "       GdPrv\tGood Privacy\n",
    "       MnPrv\tMinimum Privacy\n",
    "       GdWo\tGood Wood\n",
    "       MnWw\tMinimum Wood/Wire\n",
    "       NA\tNo Fence\n",
    "\t\n",
    "**MiscFeature**: Miscellaneous feature not covered in other categories\n",
    "\t\t\n",
    "       Elev\tElevator\n",
    "       Gar2\t2nd Garage (if not described in garage section)\n",
    "       Othr\tOther\n",
    "       Shed\tShed (over 100 SF)\n",
    "       TenC\tTennis Court\n",
    "       NA\tNone\n",
    "\t\t\n",
    "**MiscVal**: $Value of miscellaneous feature\n",
    "\n",
    "**MoSold**: Month Sold (MM)\n",
    "\n",
    "**YrSold**: Year Sold (YYYY)\n",
    "\n",
    "**SaleType**: Type of sale\n",
    "\t\t\n",
    "       WD \tWarranty Deed - Conventional\n",
    "       CWD\tWarranty Deed - Cash\n",
    "       VWD\tWarranty Deed - VA Loan\n",
    "       New\tHome just constructed and sold\n",
    "       COD\tCourt Officer Deed/Estate\n",
    "       Con\tContract 15% Down payment regular terms\n",
    "       ConLw\tContract Low Down payment and low interest\n",
    "       ConLI\tContract Low Interest\n",
    "       ConLD\tContract Low Down\n",
    "       Oth\tOther\n",
    "\t\t\n",
    "**SaleCondition**: Condition of sale\n",
    "\n",
    "       Normal\tNormal Sale\n",
    "       Abnorml\tAbnormal Sale -  trade, foreclosure, short sale\n",
    "       AdjLand\tAdjoining Land Purchase\n",
    "       Alloca\tAllocation - two linked properties with separate deeds, typically condo with a garage unit\t\n",
    "       Family\tSale between family members\n",
    "       Partial\tHome was not completed when last assessed (associated with New Homes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 The following categorical columns have one level `NA`, which might be erroneously considered as missing value by pandas:-\n",
    "\n",
    "\n",
    "- `Alley` :  NA =  No alley access\n",
    "- `BsmtQual`, `BsmtCond`, `BsmtExposure`, `BsmtFinType1`, `BsmtFinType2` : NA = No Basement\n",
    "- `FireplaceQu` : NA = No Fireplace\n",
    "- `GarageType`, `GarageFinish`, `GarageQual`, `GarageCond` : NA = No Garage\n",
    "- `PoolQC` : NA = No Pool\n",
    "- `Fence` : NA = No Fence\n",
    "- `MiscFeature` : NA = None\n",
    "\n",
    "\n",
    "So, we will have to replace these by 'None' before finding missing values.\n",
    "\n",
    "\n",
    "For this we will read the csv file again and set the parameter 'keep_default_na' to False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.943169Z",
     "iopub.status.idle": "2023-12-13T14:47:10.943643Z"
    }
   },
   "outputs": [],
   "source": [
    "## Preventing 'NA' to be read as 'NaN' by pandas\n",
    "df = pd.read_csv('../input/surprise-housing-data/train.csv', keep_default_na=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.944873Z",
     "iopub.status.idle": "2023-12-13T14:47:10.945585Z"
    }
   },
   "outputs": [],
   "source": [
    "## Replacing all 'NA' of all above mentioned columns by 'None'\n",
    "df[['Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']] = df[['Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']].replace(\"NA\", \"None\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.946519Z",
     "iopub.status.idle": "2023-12-13T14:47:10.947005Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check the info of our data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 Looking at the data types of all columns and comparing them with the data description of each columns, we deduce that the types of following columns have to be changed:\n",
    "\n",
    "- Columns `MSSubClass`, `OverallQual`, `OverallCond` need to be converted to **object** type\n",
    "- Column `LotFrontage` and `MasVnrArea` needs to be converted to **numeric** type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.947957Z",
     "iopub.status.idle": "2023-12-13T14:47:10.948444Z"
    }
   },
   "outputs": [],
   "source": [
    "## Convert three columns to 'object' type as mentioned above\n",
    "df[['MSSubClass', 'OverallQual', 'OverallCond']] = df[['MSSubClass', 'OverallQual', 'OverallCond']].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.949362Z",
     "iopub.status.idle": "2023-12-13T14:47:10.949822Z"
    }
   },
   "outputs": [],
   "source": [
    "## Convert two columns to 'numeric' type as mentioned above\n",
    "df['LotFrontage'] = pd.to_numeric(df['LotFrontage'], errors='coerce')\n",
    "df['MasVnrArea'] = pd.to_numeric(df['MasVnrArea'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.950736Z",
     "iopub.status.idle": "2023-12-13T14:47:10.951233Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check whether the data types of five columns have changed\n",
    "df[['MSSubClass', 'OverallQual', 'OverallCond', 'LotFrontage', 'MasVnrArea']].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.952145Z",
     "iopub.status.idle": "2023-12-13T14:47:10.952599Z"
    }
   },
   "outputs": [],
   "source": [
    "## View the statistical description of the numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 The mean of few variables like `2ndFlrSF` are very different from their median values, so they have skewed distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.953591Z",
     "iopub.status.idle": "2023-12-13T14:47:10.954106Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Check for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 There are only two columns containing missing values : `LotFrontage` and `MasVnrArea`,  and we will perform missing value treatment on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=cornflowerblue>Step 2: 🕵️ Data Exploration 🕵️</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=palevioletred>Univariate Analysis</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.955094Z",
     "iopub.status.idle": "2023-12-13T14:47:10.955564Z"
    }
   },
   "outputs": [],
   "source": [
    "## First let's analyse the target variable 'SalePrice'\n",
    "plt.figure(figsize=[10,8])\n",
    "sns.set_style('darkgrid')\n",
    "sns.distplot(df['SalePrice']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 The target variable is right-skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.956727Z",
     "iopub.status.idle": "2023-12-13T14:47:10.957236Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check the skewness of target variable\n",
    "df['SalePrice'].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 The skewness is greater than 1, so the target variable is highly skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.958604Z",
     "iopub.status.idle": "2023-12-13T14:47:10.959100Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check the kurtosis of target variable\n",
    "df['SalePrice'].kurt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 The kurtosis is greater than 1, so the distribution of target variable is highly peaked.\n",
    "### 📌 So, we will log transform our target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.960364Z",
     "iopub.status.idle": "2023-12-13T14:47:10.960882Z"
    }
   },
   "outputs": [],
   "source": [
    "## Log transform the target variable\n",
    "df['SalePrice'] = np.log(df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.961868Z",
     "iopub.status.idle": "2023-12-13T14:47:10.962402Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check the skewness of target variable again\n",
    "df['SalePrice'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.963715Z",
     "iopub.status.idle": "2023-12-13T14:47:10.964220Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check the kurtosis of target variable again\n",
    "df['SalePrice'].kurt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 Both skewness and kurtosis are less than 1 now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.965273Z",
     "iopub.status.idle": "2023-12-13T14:47:10.965742Z"
    }
   },
   "outputs": [],
   "source": [
    "## Plot the spread of transformed target variable\n",
    "plt.figure(figsize=[10,8])\n",
    "sns.distplot(df['SalePrice']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 So, our target variable has normal distribution now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.966691Z",
     "iopub.status.idle": "2023-12-13T14:47:10.967261Z"
    }
   },
   "outputs": [],
   "source": [
    "## Divide the dataframe df into numerical and categorical columns for EDA\n",
    "\n",
    "## Extract numerical columns\n",
    "df_num = df.select_dtypes(include=['int64', 'float64'])\n",
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.968338Z",
     "iopub.status.idle": "2023-12-13T14:47:10.968817Z"
    }
   },
   "outputs": [],
   "source": [
    "## Extract categorical columns\n",
    "df_cat = df.select_dtypes(include='object')\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA on Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.969890Z",
     "iopub.status.idle": "2023-12-13T14:47:10.970393Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## View the distribution of all numeric variables using histograms and boxplots\n",
    "\n",
    "for col in df_num.columns:\n",
    "    plt.figure(figsize=(15,5))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(col, fontdict={'fontsize': 18})\n",
    "    sns.distplot(df_num[col])\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    sns.boxplot(df_num[col])\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 Many of the numerical columns are having non-normal distribution.  \n",
    "### 📌 Most of the columns have outliers. So, we will require to do Outlier treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA on Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.971716Z",
     "iopub.status.idle": "2023-12-13T14:47:10.972241Z"
    }
   },
   "outputs": [],
   "source": [
    "## View the unique values of all Categorical columns\n",
    "for col in df_cat.columns:\n",
    "    print(col)\n",
    "    print(df[col].unique(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.973712Z",
     "iopub.status.idle": "2023-12-13T14:47:10.974391Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Visualizing the levels of categorical columns using bar plots\n",
    "for col in df_cat.columns:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.title(col, fontdict={'fontsize': 18})\n",
    "    sns.barplot(df_cat[col].value_counts().index, df_cat[col].value_counts())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 So we observe from above value counts and bar plots that there is no column with single unique value that we could remove."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=palevioletred>Bivariate Analysis</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.975450Z",
     "iopub.status.idle": "2023-12-13T14:47:10.975999Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot heatmap to detect correlations among numerical variables\n",
    "plt.figure(figsize=(25,20))\n",
    "sns.heatmap(df_num.corr(), annot=True, cmap='RdYlGn');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 Many columns are highly correlated with each other.  \n",
    "### 📌 Target variable `SalePrice` is highly correlated with `GrLivArea`, `GarageCars` and `GarageArea`.  \n",
    "### 📌 As there is multicollinearity among predictors in our data, it would be good to use Ridge Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=cornflowerblue>Step 3: 🏷️ Feature Engineering 🏷️</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.977371Z",
     "iopub.status.idle": "2023-12-13T14:47:10.978136Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create new column for the age of the house\n",
    "df['Age'] = df['YrSold'] - df['YearBuilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.979430Z",
     "iopub.status.idle": "2023-12-13T14:47:10.980140Z"
    }
   },
   "outputs": [],
   "source": [
    "## Drop the two columns from which we created new one\n",
    "df.drop(['YrSold', 'YearBuilt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.982305Z",
     "iopub.status.idle": "2023-12-13T14:47:10.982828Z"
    }
   },
   "outputs": [],
   "source": [
    "## View the dataframe again\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=cornflowerblue>Step 4: ⚙️ Data Preprocessing ⚙️</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=palevioletred>Missing Value Treatment</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.983986Z",
     "iopub.status.idle": "2023-12-13T14:47:10.984495Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## View the missing values in all features\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 There are missing values only in two columns `LotFrontage` and `MasVnrArea`       \n",
    "### 📌 As they are numerical columns, we will replace the missing values by mean value of the respective columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.985638Z",
     "iopub.status.idle": "2023-12-13T14:47:10.986169Z"
    }
   },
   "outputs": [],
   "source": [
    "## Replacing missing values in the above meniioned two columns by their means\n",
    "df['LotFrontage'].fillna(df['LotFrontage'].mean(), inplace=True)\n",
    "df['MasVnrArea'].fillna(df['MasVnrArea'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.987229Z",
     "iopub.status.idle": "2023-12-13T14:47:10.987740Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Check for missing values again \n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌Now, our data is clean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=palevioletred>Dummy Variable Creation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.988751Z",
     "iopub.status.idle": "2023-12-13T14:47:10.989278Z"
    }
   },
   "outputs": [],
   "source": [
    "## Separate the categorical and numerical features again from original dataframe\n",
    "## (as we have added one feature and removed two from original data)\n",
    "df_num = df.select_dtypes(include=['int64', 'float64'])\n",
    "df_cat = df.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.990282Z",
     "iopub.status.idle": "2023-12-13T14:47:10.990785Z"
    }
   },
   "outputs": [],
   "source": [
    "## One hot encoding the categorical columns\n",
    "df_cat_encoded = pd.get_dummies(df_cat, drop_first=True)\n",
    "df_cat_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.991820Z",
     "iopub.status.idle": "2023-12-13T14:47:10.992349Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check the dimensions\n",
    "df_cat_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=palevioletred>Outlier treatment</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.993574Z",
     "iopub.status.idle": "2023-12-13T14:47:10.994103Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check the boxplots to view outliers in numerical columns\n",
    "plt.figure(figsize=[15,15])\n",
    "plt.xticks(rotation=90)\n",
    "sns.boxplot(data=df_num);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.995488Z",
     "iopub.status.idle": "2023-12-13T14:47:10.996004Z"
    }
   },
   "outputs": [],
   "source": [
    "## Capping outliers to 5% at lower bound and 95% at upper bound\n",
    "for col in df_num.columns:\n",
    "    df_num[col][df_num[col] <= df_num[col].quantile(0.05)] = df_num[col].quantile(0.05)\n",
    "    df_num[col][df_num[col] >= df_num[col].quantile(0.95)] = df_num[col].quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.997005Z",
     "iopub.status.idle": "2023-12-13T14:47:10.997514Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check the boxplots again to see if outliers have been treated\n",
    "plt.figure(figsize=[15,15])\n",
    "plt.xticks(rotation=90)\n",
    "sns.boxplot(data=df_num);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 So, we have removed outliers from all numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:10.998544Z",
     "iopub.status.idle": "2023-12-13T14:47:10.999385Z"
    }
   },
   "outputs": [],
   "source": [
    "## Concatenate the outlier treated numerical columns with one hot encoded categorical columns\n",
    "df = pd.concat([df_num, df_cat_encoded], axis=1)\n",
    "\n",
    "\n",
    "## View the first few rows of our dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 Now, our dataframe is ready for model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=cornflowerblue>Step 5: 🏗️ Model Building, Tuning and Evaluation 🏗️</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=palevioletred>Split the Data into Dependent and Independent variables</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.000537Z",
     "iopub.status.idle": "2023-12-13T14:47:11.001248Z"
    }
   },
   "outputs": [],
   "source": [
    "## X contains all independent variables use to make predictions except 'Id' (not useful) and 'SalePrice' (target variable)\n",
    "X = df.drop([\"Id\", \"SalePrice\"], axis=1).copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.002426Z",
     "iopub.status.idle": "2023-12-13T14:47:11.003007Z"
    }
   },
   "outputs": [],
   "source": [
    "## Separate out the target variable as y which we want to predict\n",
    "y = df[\"SalePrice\"].copy()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=palevioletred>Train - Test Split</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.004163Z",
     "iopub.status.idle": "2023-12-13T14:47:11.004676Z"
    }
   },
   "outputs": [],
   "source": [
    "## Splitting X and y into 80% train data and 20% test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.006065Z",
     "iopub.status.idle": "2023-12-13T14:47:11.006625Z"
    }
   },
   "outputs": [],
   "source": [
    "## View dimensions of train data\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.007613Z",
     "iopub.status.idle": "2023-12-13T14:47:11.008142Z"
    }
   },
   "outputs": [],
   "source": [
    "## View dimensions of test data\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=palevioletred>Scaling numerical columns</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.009186Z",
     "iopub.status.idle": "2023-12-13T14:47:11.009675Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create a list of numerical columns to be scaled\n",
    "num_cols = list(X_train.select_dtypes(include=['int64', 'float64']).columns)\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.010756Z",
     "iopub.status.idle": "2023-12-13T14:47:11.011285Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create a scaling instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "## Scale the numerical columns \n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=teal>Model 1: Ridge Regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.012399Z",
     "iopub.status.idle": "2023-12-13T14:47:11.013089Z"
    }
   },
   "outputs": [],
   "source": [
    "## Define a function for checking metrics \n",
    "def show_metrics(y_train, y_train_pred, y_test, y_pred):\n",
    "    ''' \n",
    "    Takes in the values of true y_train and y_test, and predicted y_train and y_test.\n",
    "    Prints out \n",
    "    1. R-Squared (Train)\n",
    "    2. R-Squared (Test)\n",
    "    3. RSS (Train)\n",
    "    4. RSS (Test)\n",
    "    5. MSE (Train)\n",
    "    6. MSE (Test)\n",
    "    7. RMSE (Train)\n",
    "    8. RMSE (Test)\n",
    "    \n",
    "    Returns a list containing all the above 8 metrics\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ## Create a list to save all metrics (will be used in creating a final summary in the end)\n",
    "    metric = []\n",
    "    \n",
    "    ## R-squared of train and test data\n",
    "    print(\"R-Squared (Train) =\", '%.2f' % r2_score(y_train, y_train_pred))\n",
    "    metric.append(r2_score(y_train, y_train_pred))\n",
    "    print(\"R-Squared (Test) =\", '%.2f' % r2_score(y_test, y_pred))\n",
    "    metric.append(r2_score(y_test, y_pred))\n",
    "    \n",
    "    ## Residual sum of squares of train and test data\n",
    "    rss_train = np.sum(np.square(y_train - y_train_pred))\n",
    "    metric.append(rss_train)\n",
    "    rss_test = np.sum(np.square(y_test - y_pred))\n",
    "    metric.append(rss_test)\n",
    "    print(\"RSS (Train) =\", '%.2f' % rss_train)\n",
    "    print(\"RSS (Test) =\", '%.2f' % rss_test)\n",
    "    \n",
    "    \n",
    "    ## Mean Squared Error of train and test data\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    metric.append(mse_train)\n",
    "    mse_test = mean_squared_error(y_test, y_pred)\n",
    "    metric.append(mse_test)\n",
    "    print(\"MSE (Train) =\", '%.2f' % mse_train)\n",
    "    print(\"MSE (Test) =\", '%.2f' % mse_test)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Root Mean Squared Error for train and test data\n",
    "    rmse_train = mse_train**0.5\n",
    "    metric.append(rmse_train)\n",
    "    rmse_test = mse_test**0.5\n",
    "    metric.append(rmse_test)\n",
    "    print(\"RMSE (Train) =\", '%.2f' % rmse_train) \n",
    "    print(\"RMSE (Test) =\", '%.2f' % rmse_test) \n",
    "    \n",
    "\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.014193Z",
     "iopub.status.idle": "2023-12-13T14:47:11.014678Z"
    }
   },
   "outputs": [],
   "source": [
    "## Now to create a Ridge Regression model\n",
    "## we will run a cross validation on a list of alphas to find the optimum value of alpha\n",
    "\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\n",
    "                    2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000]}\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "# cross validation\n",
    "\n",
    "ridgeCV = GridSearchCV(estimator = ridge, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error',  \n",
    "                        cv = 5, \n",
    "                        return_train_score=True,\n",
    "                        verbose = 1, n_jobs=-1)            \n",
    "ridgeCV.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.015781Z",
     "iopub.status.idle": "2023-12-13T14:47:11.016312Z"
    }
   },
   "outputs": [],
   "source": [
    "## View the optimal value of alpha\n",
    "ridgeCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.017573Z",
     "iopub.status.idle": "2023-12-13T14:47:11.018117Z"
    }
   },
   "outputs": [],
   "source": [
    "## View the results of cross validation search\n",
    "ridgeCV.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 Thus, we get optimum value of alpha as 10. Now we will build a ridge regression model using this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.019468Z",
     "iopub.status.idle": "2023-12-13T14:47:11.019995Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a ridge regreesion instance with optimum value alpha=10\n",
    "ridge = Ridge(alpha=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.021034Z",
     "iopub.status.idle": "2023-12-13T14:47:11.021537Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model on training data\n",
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.022736Z",
     "iopub.status.idle": "2023-12-13T14:47:11.023261Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## View the coefficients of ridge regression fitted model\n",
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.024447Z",
     "iopub.status.idle": "2023-12-13T14:47:11.025017Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make predictions\n",
    "y_train_pred = ridge.predict(X_train)\n",
    "y_pred = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.031965Z",
     "iopub.status.idle": "2023-12-13T14:47:11.032745Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check metrics\n",
    "ridge_metrics = show_metrics(y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we will plot R2 Score against different values of alpha for both train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.034906Z",
     "iopub.status.idle": "2023-12-13T14:47:11.035644Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Create a dataframe of ridge cross validation results\n",
    "ridgeCV_results= pd.DataFrame(ridgeCV.cv_results_)\n",
    "ridgeCV_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.037559Z",
     "iopub.status.idle": "2023-12-13T14:47:11.038292Z"
    }
   },
   "outputs": [],
   "source": [
    "## Plotting R2 score vs alpha values\n",
    "plt.plot(ridgeCV_results['param_alpha'], ridgeCV_results['mean_train_score'], label='Train')\n",
    "plt.plot(ridgeCV_results['param_alpha'], ridgeCV_results['mean_test_score'], label='Test')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('R2_score')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 As the value of alpha increases, we see a decrease in train error and an initial increase followed by decrease in test error.\n",
    "### 📌 From graph also, it is apparent that the optimal value of alpha is 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=teal>Model 2: Lasso<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.039816Z",
     "iopub.status.idle": "2023-12-13T14:47:11.040538Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Now to create a Lasso model\n",
    "## we will run a cross validation on a list of alphas to find the optimum value of alpha\n",
    "\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\n",
    "                    2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000]}\n",
    "\n",
    "lasso = Lasso()\n",
    "\n",
    "# cross validation\n",
    "\n",
    "lassoCV = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error',  \n",
    "                        cv = 5, \n",
    "                        return_train_score=True,\n",
    "                        verbose = 1, n_jobs=-1)            \n",
    "lassoCV.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.042006Z",
     "iopub.status.idle": "2023-12-13T14:47:11.042620Z"
    }
   },
   "outputs": [],
   "source": [
    "## View the optimal value of alpha\n",
    "lassoCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.051749Z",
     "iopub.status.idle": "2023-12-13T14:47:11.052528Z"
    }
   },
   "outputs": [],
   "source": [
    "## View the results of cross validation search\n",
    "lassoCV.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 Thus, we get optimum value of alpha as 0.001. Now we will build a lasso regression model using this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.053898Z",
     "iopub.status.idle": "2023-12-13T14:47:11.054615Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a ridge regreesion instance with optimum value alpha=0.001\n",
    "lasso = Lasso(alpha=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.056216Z",
     "iopub.status.idle": "2023-12-13T14:47:11.056908Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model on training data\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.058269Z",
     "iopub.status.idle": "2023-12-13T14:47:11.058950Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## View the coefficients of lasso fitted model\n",
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.060698Z",
     "iopub.status.idle": "2023-12-13T14:47:11.061403Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make predictions\n",
    "y_train_pred = lasso.predict(X_train)\n",
    "y_pred = lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.062891Z",
     "iopub.status.idle": "2023-12-13T14:47:11.063595Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check metrics\n",
    "lasso_metrics = show_metrics(y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we will plot R2 Score against different values of alpha for both train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.064964Z",
     "iopub.status.idle": "2023-12-13T14:47:11.065659Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Create a dataframe of ridge cross validation results\n",
    "lassoCV_results= pd.DataFrame(lassoCV.cv_results_)\n",
    "lassoCV_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.067097Z",
     "iopub.status.idle": "2023-12-13T14:47:11.067766Z"
    }
   },
   "outputs": [],
   "source": [
    "## Plotting R2 score vs alpha values\n",
    "plt.plot(lassoCV_results['param_alpha'], lassoCV_results['mean_train_score'], label='Train')\n",
    "plt.plot(lassoCV_results['param_alpha'], lassoCV_results['mean_test_score'], label='Test')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('R2_score')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 As the value of alpha increases, we see a decrease in both train and test error. \n",
    "### 📌 However, after a error value of approximately 0.05, error remains constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=cornflowerblue>Step 6: 📊 Comparing the two models 📊</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.069499Z",
     "iopub.status.idle": "2023-12-13T14:47:11.070020Z"
    }
   },
   "outputs": [],
   "source": [
    "## Setting float display options\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.071252Z",
     "iopub.status.idle": "2023-12-13T14:47:11.071747Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a table which contain all the metrics\n",
    "\n",
    "lr_table = {'Metric': ['R2 Score (Train)','R2 Score (Test)','RSS (Train)','RSS (Test)',\n",
    "                       'MSE (Train)','MSE (Test)', 'RMSE (Train)', 'RMSE (Test)'],\n",
    "            'Ridge Regression' : ridge_metrics,\n",
    "            'Lasso Regression' : lasso_metrics\n",
    "        }\n",
    "\n",
    "final_metric = pd.DataFrame(lr_table, columns = ['Metric', 'Ridge Regression', 'Lasso Regression'] )\n",
    "final_metric.set_index('Metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 The R2 score on test data is 0.93 for both Ridge Regression and Lasso models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.073152Z",
     "iopub.status.idle": "2023-12-13T14:47:11.073711Z"
    }
   },
   "outputs": [],
   "source": [
    "## Now we see the changes in coefficients after regularization\n",
    "\n",
    "## First create empty datafame with all the independent variables as indices\n",
    "betas = pd.DataFrame(index=X.columns)\n",
    "betas.rows = X.columns\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.074935Z",
     "iopub.status.idle": "2023-12-13T14:47:11.075471Z"
    }
   },
   "outputs": [],
   "source": [
    "## Now fill in the values of betas, one column for ridge coefficients and one for lasso coefficients\n",
    "betas['Ridge'] = ridge.coef_\n",
    "betas['Lasso'] = lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.076545Z",
     "iopub.status.idle": "2023-12-13T14:47:11.077068Z"
    }
   },
   "outputs": [],
   "source": [
    "## View the betas/coefficients\n",
    "betas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.078317Z",
     "iopub.status.idle": "2023-12-13T14:47:11.078822Z"
    }
   },
   "outputs": [],
   "source": [
    "## View the features removed by Lasso\n",
    "betas[betas['Lasso']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.082368Z",
     "iopub.status.idle": "2023-12-13T14:47:11.082834Z"
    }
   },
   "outputs": [],
   "source": [
    "## View the number of features removed by lasso\n",
    "betas[betas['Lasso']==0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 The above 306 features out of 384 (from X_train) have been removed by Lasso. In this way, lasso performs feature selection\n",
    "### 📌 Below are the features selected by Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T14:47:11.084540Z",
     "iopub.status.busy": "2023-12-13T14:47:11.084236Z",
     "iopub.status.idle": "2023-12-13T14:47:11.106361Z",
     "shell.execute_reply": "2023-12-13T14:47:11.104881Z",
     "shell.execute_reply.started": "2023-12-13T14:47:11.084509Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'betas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ec8acc2cf968>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## View the features selected by lasso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbetas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lasso'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Lasso'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'betas' is not defined"
     ]
    }
   ],
   "source": [
    "## View the features selected by lasso\n",
    "betas.loc[betas['Lasso']!=0, 'Lasso']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=cornflowerblue>Step 7: ☑️ Inferences for 'Surprise Housing' ☑️</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we will look at the top 10 features significant in predicting the value of a house, both according to Ridge model and Lasso model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.107334Z",
     "iopub.status.idle": "2023-12-13T14:47:11.107817Z"
    }
   },
   "outputs": [],
   "source": [
    "## View the top 10 coefficients of Ridge regression in descending order\n",
    "betas['Ridge'].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.108906Z",
     "iopub.status.idle": "2023-12-13T14:47:11.109425Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## To interpret the ridge coefficients in terms of target, we have to take inverse log (i.e. e to the power) of betas\n",
    "ridge_coeffs = np.exp(betas['Ridge'])\n",
    "ridge_coeffs.sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.110475Z",
     "iopub.status.idle": "2023-12-13T14:47:11.110952Z"
    }
   },
   "outputs": [],
   "source": [
    "## View the top 10 coefficients of Lasso in descending order\n",
    "betas['Lasso'].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.111994Z",
     "iopub.status.idle": "2023-12-13T14:47:11.112455Z"
    }
   },
   "outputs": [],
   "source": [
    "## To interpret the lasso coefficients in terms of target, we have to take inverse log (i.e. 10 to the power) of betas\n",
    "lasso_coeffs = np.exp(betas['Lasso'])\n",
    "lasso_coeffs.sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferences:\n",
    "### 📌 The variables significant in predicting the price of a house are: - \n",
    "`GrLivArea`, `OverallQual_9`, `OverallCond_9`, `OverallQual_8`, `Neighborhood_Crawfor`, `Functional_Typ`, `Exterior1st_BrkFace`, `SaleCondition_Alloca`, `CentralAir_Y`, `TotalBsmtSF`, `Neighborhood_Somerst`, `TotalBsmtSF` and `Condition1_Norm`          \n",
    "\n",
    "\n",
    "### 📌 How well those variables describe the price of a house?\n",
    "Here will see only top few variables\n",
    "- `GrLivArea`:an increase of 1 square foot of house area above ground, the price will increase by 1.09 to 1.11 times\n",
    "- `OverallQual_9` & `OverallQual_8`: if the overall material and finish of the house is **Very Good** or **Excellent**, the price of house will increase by 1.08 to 1.13 times\n",
    "- `Neighborhood_Crawfor`: if Crawford is a nearby location, then the price of house will increase by 1.07 to 1.09 times\n",
    "- `Functional_Typ`: if the home functionality is typical, then the price of house will increase by 1.07 to 1.08 times\n",
    "- `Exterior1st_BrkFace`: if the exterior covering on the house is **Brick Face**, the price of house will increase by 1.07 to 1.08 times.\n",
    "\n",
    "In a similar manner, we can deduct how well each variable describes the price of a house.\n",
    "\n",
    "### 📌 Optimal value of lambda for Ridge Regression = 10\n",
    "\n",
    "\n",
    "### 📌 Optimal value of lambda for Lasso = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=cornflowerblue>Step 8: ✍🏻 Coding for answering the subjective questions ✍🏻</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "What is the optimal value of alpha for ridge and lasso regression? What will be the changes in the model if you choose double the value of alpha for both ridge and lasso? What will be the most important predictor variables after the change is implemented?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "\n",
    "- Optimal value of lambda for Ridge Regression = **10**\n",
    "\n",
    "\n",
    "- Optimal value of lambda for Lasso = **0.001**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.113640Z",
     "iopub.status.idle": "2023-12-13T14:47:11.114139Z"
    }
   },
   "outputs": [],
   "source": [
    "## Let us build the ridge regression model with double value of alpha i.e. 20\n",
    "ridge = Ridge(alpha=20)\n",
    "\n",
    "# Fit the model on training data\n",
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.115112Z",
     "iopub.status.idle": "2023-12-13T14:47:11.115581Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make predictions\n",
    "y_train_pred = ridge.predict(X_train)\n",
    "y_pred = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.116574Z",
     "iopub.status.idle": "2023-12-13T14:47:11.117057Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check metrics\n",
    "ridge_metrics = show_metrics(y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.118080Z",
     "iopub.status.idle": "2023-12-13T14:47:11.118536Z"
    }
   },
   "outputs": [],
   "source": [
    "## Now we will build the lasso model with double value of alpha i.e. 0.002\n",
    "lasso = Lasso(alpha=0.002)\n",
    "\n",
    "# Fit the model on training data\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.119520Z",
     "iopub.status.idle": "2023-12-13T14:47:11.120043Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make predictions\n",
    "y_train_pred = lasso.predict(X_train)\n",
    "y_pred = lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.121157Z",
     "iopub.status.idle": "2023-12-13T14:47:11.121616Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check metrics\n",
    "lasso_metrics = show_metrics(y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.122623Z",
     "iopub.status.idle": "2023-12-13T14:47:11.123112Z"
    }
   },
   "outputs": [],
   "source": [
    "# Again creating a table which contain all the metrics\n",
    "\n",
    "lr_table = {'Metric': ['R2 Score (Train)','R2 Score (Test)','RSS (Train)','RSS (Test)',\n",
    "                       'MSE (Train)','MSE (Test)', 'RMSE (Train)', 'RMSE (Test)'],\n",
    "            'Ridge Regression' : ridge_metrics,\n",
    "            'Lasso Regression' : lasso_metrics\n",
    "        }\n",
    "\n",
    "final_metric = pd.DataFrame(lr_table, columns = ['Metric', 'Ridge Regression', 'Lasso Regression'] )\n",
    "final_metric.set_index('Metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 Changes in Ridge Regression metrics:\n",
    "- R2 score of train set decreased from 0.94 to 0.93\n",
    "- R2 score of test set remained same at 0.93\n",
    "\n",
    "### 📌 Changes in Lasso metrics:\n",
    "- R2 score of train set decreased from 0.92 to 0.91\n",
    "- R2 score of test set decreased from 0.93 to 0.91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.124092Z",
     "iopub.status.idle": "2023-12-13T14:47:11.124557Z"
    }
   },
   "outputs": [],
   "source": [
    "## Now we see the changes in coefficients after regularization\n",
    "\n",
    "## First create empty datafame with all the independent variables as indices\n",
    "betas = pd.DataFrame(index=X.columns)\n",
    "betas.rows = X.columns\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.194334Z",
     "iopub.status.idle": "2023-12-13T14:47:11.194913Z"
    }
   },
   "outputs": [],
   "source": [
    "## Now fill in the values of betas, one column for ridge coefficients and one for lasso coefficients\n",
    "betas['Ridge'] = ridge.coef_\n",
    "betas['Lasso'] = lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.196408Z",
     "iopub.status.idle": "2023-12-13T14:47:11.196925Z"
    }
   },
   "outputs": [],
   "source": [
    "## View the betas/coefficients\n",
    "betas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we look at the most important predictor variables after the change is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.198517Z",
     "iopub.status.idle": "2023-12-13T14:47:11.199020Z"
    }
   },
   "outputs": [],
   "source": [
    "## View the top 10 coefficients of Ridge regression in descending order\n",
    "betas['Ridge'].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T14:47:11.226784Z",
     "iopub.status.busy": "2023-12-13T14:47:11.226388Z",
     "iopub.status.idle": "2023-12-13T14:47:11.248568Z",
     "shell.execute_reply": "2023-12-13T14:47:11.246524Z",
     "shell.execute_reply.started": "2023-12-13T14:47:11.226747Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'betas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-85f7c854d0cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## To interpret the ridge coefficients in terms of target, we have to take inverse log (i.e. e to the power) of betas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mridge_coeffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ridge'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mridge_coeffs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'betas' is not defined"
     ]
    }
   ],
   "source": [
    "## To interpret the ridge coefficients in terms of target, we have to take inverse log (i.e. e to the power) of betas\n",
    "ridge_coeffs = np.exp(betas['Ridge'])\n",
    "ridge_coeffs.sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.249631Z",
     "iopub.status.idle": "2023-12-13T14:47:11.250166Z"
    }
   },
   "outputs": [],
   "source": [
    "## View the top 10 coefficients of Lasso in descending order\n",
    "betas['Lasso'].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.251127Z",
     "iopub.status.idle": "2023-12-13T14:47:11.251596Z"
    }
   },
   "outputs": [],
   "source": [
    "## To interpret the lasso coefficients in terms of target, we have to take inverse log (i.e. 10 to the power) of betas\n",
    "lasso_coeffs = np.exp(betas['Lasso'])\n",
    "lasso_coeffs.sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 So, the most important predictor variables after we double the alpha values are:-\n",
    "- `GrLivArea`\n",
    "\n",
    "\n",
    "- `OverallQual_8`\n",
    "\n",
    "\n",
    "- `OverallQual_9`\n",
    "\n",
    "\n",
    "- `Functional_Typ`\n",
    "\n",
    "\n",
    "- `Neighborhood_Crawfor`\n",
    "\n",
    "\n",
    "- `Exterior1st_BrkFace`\n",
    "\n",
    "\n",
    "- `TotalBsmtSF`\n",
    "\n",
    "\n",
    "- `CentralAir_Y`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "You have determined the optimal value of lambda for ridge and lasso regression during the assignment. Now, which one will you choose to apply and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "\n",
    "- The model we will choose to apply will depend on the use case.\n",
    "- If we have too many variables and one of our primary goal is feature selection, then we will use **Lasso**.\n",
    "- If we don't want to get too large coefficients and reduction of coefficient magnitude is one of our prime goals, then we will use **Ridge Regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "After building the model, you realised that the five most important predictor variables in the lasso model are not available in the incoming data. You will now have to create another model excluding the five most important predictor variables. Which are the five most important predictor variables now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "\n",
    "- Here, we will drop the top 5 features in Lasso model and build the model again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 5 Lasso predictors were: `OverallQual_9`, `GrLivArea`, `OverallQual_8`,`Neighborhood_Crawfor` and `Exterior1st_BrkFace`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.252491Z",
     "iopub.status.idle": "2023-12-13T14:47:11.252945Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create a list of top 5 lasso predictors that are to be removed\n",
    "top5 = ['OverallQual_9', 'GrLivArea', 'OverallQual_8', 'Neighborhood_Crawfor', 'Exterior1st_BrkFace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.253853Z",
     "iopub.status.idle": "2023-12-13T14:47:11.254349Z"
    }
   },
   "outputs": [],
   "source": [
    "## drop them from train and test data\n",
    "X_train_dropped = X_train.drop(top5, axis=1)\n",
    "X_test_dropped = X_test.drop(top5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.255252Z",
     "iopub.status.idle": "2023-12-13T14:47:11.255710Z"
    }
   },
   "outputs": [],
   "source": [
    "## Now to create a Lasso model\n",
    "## we will run a cross validation on a list of alphas to find the optimum value of alpha\n",
    "\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\n",
    "                    2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000]}\n",
    "\n",
    "lasso = Lasso()\n",
    "\n",
    "# cross validation\n",
    "\n",
    "lassoCV = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error',  \n",
    "                        cv = 5, \n",
    "                        return_train_score=True,\n",
    "                        verbose = 1, n_jobs=-1)            \n",
    "lassoCV.fit(X_train_dropped, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.256707Z",
     "iopub.status.idle": "2023-12-13T14:47:11.257230Z"
    }
   },
   "outputs": [],
   "source": [
    "## View the optimal value of alpha\n",
    "lassoCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 Thus, we get optimum value of alpha as 0.001. Now we will build a lasso regression model using this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.258386Z",
     "iopub.status.idle": "2023-12-13T14:47:11.258849Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a lasso instance with optimum value alpha=0.001\n",
    "lasso = Lasso(alpha=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.259779Z",
     "iopub.status.idle": "2023-12-13T14:47:11.260294Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model on training data\n",
    "lasso.fit(X_train_dropped, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.261388Z",
     "iopub.status.idle": "2023-12-13T14:47:11.261892Z"
    }
   },
   "outputs": [],
   "source": [
    "## Make predictions\n",
    "y_train_pred = lasso.predict(X_train_dropped)\n",
    "y_pred = lasso.predict(X_test_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.263243Z",
     "iopub.status.idle": "2023-12-13T14:47:11.263774Z"
    }
   },
   "outputs": [],
   "source": [
    "## Check metrics\n",
    "lasso_metrics = show_metrics(y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we will find the top 5 predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.265150Z",
     "iopub.status.idle": "2023-12-13T14:47:11.265658Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a table which contain all the metrics\n",
    "\n",
    "lr_table = {'Metric': ['R2 Score (Train)','R2 Score (Test)','RSS (Train)','RSS (Test)',\n",
    "                       'MSE (Train)','MSE (Test)', 'RMSE (Train)', 'RMSE (Test)'],\n",
    "            'Lasso Regression' : lasso_metrics\n",
    "        }\n",
    "\n",
    "final_metric = pd.DataFrame(lr_table, columns = ['Metric', 'Lasso Regression'] )\n",
    "final_metric.set_index('Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.267094Z",
     "iopub.status.idle": "2023-12-13T14:47:11.267599Z"
    }
   },
   "outputs": [],
   "source": [
    "## Now we see the changes in coefficients after regularization\n",
    "\n",
    "## First create empty datafame with all the independent variables as indices\n",
    "betas = pd.DataFrame(index=X_train_dropped.columns)\n",
    "betas.rows = X_train_dropped.columns\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.268958Z",
     "iopub.status.idle": "2023-12-13T14:47:11.269509Z"
    }
   },
   "outputs": [],
   "source": [
    "## Now fill in the values of betas, one column for ridge coefficients and one for lasso coefficients\n",
    "betas['Lasso'] = lasso.coef_\n",
    "# betas['Lasso'] = lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.270524Z",
     "iopub.status.idle": "2023-12-13T14:47:11.271046Z"
    }
   },
   "outputs": [],
   "source": [
    "## View the betas/coefficients\n",
    "betas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we will look at the top 5 features significant in predicting the value of a house according to the new lasso model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-13T14:47:11.272164Z",
     "iopub.status.idle": "2023-12-13T14:47:11.272675Z"
    }
   },
   "outputs": [],
   "source": [
    "## View the top 5 coefficients of Lasso in descending order\n",
    "betas['Lasso'].sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 After dropping our top 5 lasso predictors, we get the following new top 5 predictors:-\n",
    "\n",
    "- `2ndFlrSF`\n",
    "\n",
    "\n",
    "- `Functional_Typ`\n",
    "\n",
    "\n",
    "- `1stFlrSF`\n",
    "\n",
    "\n",
    "- `MSSubClass_70`\n",
    "\n",
    "\n",
    "- `Neighborhood_Somerst`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "How can you make sure that a model is robust and generalisable? What are the implications of the same for the accuracy of the model and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A model is **robust** when any variation in the data does not affect its performance much. \n",
    "- A **generalizable** model is able to adapt properly to new, previously unseen data, drawn from the same distribution as the one used to create the model.\n",
    "- To make sure a model is robust and generalizable, we have to **take care it doesn't overfit**. This is because an overfitting model has very high variance and a smallest change in data affects the model prediction heavily. Such a model will identify all the patterns of a training data, but fail to pick up the patterns in unseen test data.\n",
    "- In other words, the model should not be too complex in order to be robust and generalizable.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- If we look at it from the prespective of **Accuracy**, a too complex model will have a very high accuracy. So, to make our model more robust and generalizable, we will have to decrease variance which will lead to some bias. Addition of bias means that accuracy will decrease.\n",
    "- In general, we have to find strike some balance between model accuracy and complexity. This can be achieved by Regularization techniques like Ridge Regression and Lasso.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1401304,
     "sourceId": 2321622,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4037188,
     "sourceId": 7020742,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30096,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
